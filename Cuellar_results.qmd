---
title: "R skills results"
author: Christian Cuellar
date: "2023-11-13"
format: html
editor: visual
---

## Introduction

This document shows the results of the R skills assessment.

```{r echo=FALSE, results='hide'}
library(ggplot2)
library(scales)
library(tidyverse)
library(DT)
library(Hmisc)
library(scales)
library(forcats)
library(waldo)
library(wbpip)
library(purrr)

```

```{r echo=FALSE, results='hide'}

#Reading data
tag      <- "master"
base_url <- "https://github.com/randrescastaneda/pub_data/raw/"
data_url <- paste0(base_url, tag, "/data/Rtest1/")

wdi <-
  readr::read_rds(paste0(data_url, "wdi_in1.Rds"))


```

## 1. Summary statistics of GDP per capita by region

The following table presents a statistical summary of the GDP per capita across different regions and years. Each row corresponds to a specific region-year and displays key descriptive metrics that characterize the distribution of GDP per capita within that region. The metrics include the mean, standard deviation (variability), minimum, and maximum values.

```{r}

summary_stats <- wdi %>%
  group_by(region, date) %>%
  summarise(N = n(),
            Mean = comma(round(sum(gdp * pop, na.rm = TRUE) / sum(pop[!is.na(gdp)], na.rm = TRUE), 0)),
            SD = comma(round(sqrt(wtd.var(gdp[!is.na(gdp) & !is.na(pop)], pop[!is.na(gdp) & !is.na(pop)])), 0)), 
            Min = comma(round(min(gdp, na.rm = TRUE), 0)),
            Max = comma(round(max(gdp, na.rm = TRUE), 0))
            )

DT::datatable(summary_stats, filter = 'top', 
          options = list( pageLength = 10, autoWidth = TRUE)) 



```

```{r echo=FALSE, results='hide'}
# Differences are related to rounding data
wdi_summ_out <- readr::read_rds(paste0(data_url, "wdi_summ_out.Rds"))
difference <- waldo::compare(wdi_summ_out, summary_stats)
```

## 2. Aggregate stats

The following table presents the aggregated statistics the GDP per capita across, life expectancy, and population living in poverty. The metrics include the mean, standard deviation, minimum, maximum and mean values.

```{r}

agg_stats <- wdi %>%
  group_by(region, date) %>%
  summarise(  mean_lifeex = sum(lifeex * pop, na.rm = TRUE) / sum(pop[!is.na(lifeex)], na.rm = TRUE),
            sd_lifeex = sqrt(wtd.var(lifeex[!is.na(lifeex) & !is.na(pop)], pop[!is.na(lifeex) & !is.na(pop)])),
            min_lifeex = min(lifeex, na.rm = TRUE),
            max_lifeex = max(lifeex, na.rm = TRUE),
            median_lifeex = median(lifeex, na.rm = TRUE),

            mean_gdp = sum(gdp * pop, na.rm = TRUE) / sum(pop[!is.na(gdp)], na.rm = TRUE),
            sd_gdp = sqrt(wtd.var(gdp[!is.na(gdp) & !is.na(pop)], pop[!is.na(gdp) & !is.na(pop)])), 
            min_gdp = min(gdp, na.rm = TRUE),
            max_gdp = max(gdp, na.rm = TRUE),
            median_gdp = median(gdp, na.rm = TRUE),
            
            mean_povintl = sum(pov_intl*pop, na.rm = TRUE) / sum(pop[!is.na(gdp)], na.rm = TRUE),
            sd_povintl = sqrt(wtd.var(pov_intl[!is.na(pov_intl) & !is.na(pop)], pop[!is.na(pov_intl) & !is.na(pop)])),
            min_povintl = min(pov_intl, na.rm = TRUE),
            max_povintl = max(pov_intl, na.rm = TRUE),
            median_povintl = median(pov_intl, na.rm = TRUE),
            
            population = sum(pop, na.rm = TRUE)

            )

agg_stats_long <- agg_stats %>%
  pivot_longer(
    cols = -c(region, date, population), 
    names_to = c("estimate", ".value"),
    names_pattern = "(.+)_(.+)"
  ) %>%
  rename(pop = population, pov_intl = povintl) %>%
  select(estimate, region, date, pop, lifeex, gdp, pov_intl) %>%
  mutate(estimate = fct_relevel(estimate, "mean", "sd", "min", "max", "median")) %>%
  arrange(estimate)

DT::datatable(agg_stats_long, filter = 'top', 
          options = list( pageLength = 10, autoWidth = TRUE)) 


```

## 3. Find outliers

```{r}


mean_sd_year <- wdi %>%
  group_by(date) %>%
  summarise(
    
  # Omit NA values in both pop and gdp variables
  mean_gdp = sum(gdp * pop, na.rm = TRUE) / sum(pop[!is.na(gdp)], na.rm = TRUE),
  sd_gdp = sqrt(wtd.var(gdp[!is.na(gdp) & !is.na(pop)], pop[!is.na(gdp) & !is.na(pop)])),
    
  mean_lifeex = sum(lifeex * pop, na.rm = TRUE) / sum(pop[!is.na(lifeex)], na.rm = TRUE),
  sd_lifeex = sqrt(wtd.var(lifeex[!is.na(lifeex) & !is.na(pop)], pop[!is.na(lifeex) & !is.na(pop)])),

  mean_gini = sum(gini * pop, na.rm = TRUE) / sum(pop[!is.na(gini)], na.rm = TRUE),
  sd_gini = sqrt(wtd.var(gini[!is.na(gini) & !is.na(pop)], pop[!is.na(gini) & !is.na(pop)])),
  )


wdi_outliers <- wdi %>%
  left_join(mean_sd_year, by = "date")

wdi_outliers <- wdi_outliers %>%
 mutate(
    ll_gdp = gdp < (mean_gdp - 2.5 * sd_gdp),
    hl_gdp = gdp > (mean_gdp + 2.5 * sd_gdp),
    ll_lifeex = lifeex < (mean_lifeex - 2.5 * sd_lifeex),
    hl_lifeex = lifeex > (mean_lifeex + 2.5 * sd_lifeex),
    ll_gini = gini < (mean_gini - 2.5 * sd_gini),
    hl_gini = gini > (mean_gini + 2.5 * sd_gini)
  )

mean_sd_year <- mean_sd_year %>%
  mutate(
    ll_lifeex = mean_lifeex - (2.5 * sd_lifeex), 
    hl_lifeex = mean_lifeex + (2.5 * sd_lifeex)  
  )

ggplot() +
  geom_point(data = wdi_outliers, aes(x = date, y = lifeex, color = region)) + 
    geom_ribbon(data = mean_sd_year, aes(x = date, ymin = ll_lifeex, ymax = hl_lifeex), alpha = 0.2) +
  geom_line(data = mean_sd_year, aes(x = date, y = mean_lifeex)) + 
  theme_minimal() +
  labs(x = "Year", y = "Life Expectancy", color = "Region")

outliers_results <- readr::read_rds(paste0(data_url, "wdi_outliers_out.Rds"))


```

## 4. Poverty measures

```{r}
l_svy <-
    readr::read_rds(paste0(data_url, "svy_sim_in1.Rds"))

# Use a library available on Github from the World Bank
source("https://raw.githubusercontent.com/PIP-Technical-Team/wbpip/master/R/md_compute_poverty_stats.R")

l_svy_df <- l_svy %>%
  enframe(name = "year", value = "data") %>%
  unnest(data)

poverty_lines <- c(2.15, 3.65, 6.85)

# Create a dataframe with all combinations of year and poverty line
expanded_df <- l_svy_df %>%
  ungroup() %>%
  expand(year, poverty_line = poverty_lines)

# Apply md_compute_poverty_stats
results_list <- lapply(1:nrow(expanded_df), function(i) {
  row <- expanded_df[i, ]
  data <- l_svy[[row$year]]
  poverty_line <- row$poverty_line
  result <- md_compute_poverty_stats(data[["income"]], data[["weight"]], poverty_line)
  c(year = row$year, pov_line = poverty_line, result)
})

# Convert the list to a dataframe
results_df <- do.call(rbind, results_list) %>%
  as.data.frame(stringsAsFactors = FALSE) 


DT::datatable(results_df, filter = 'top', 
          options = list( pageLength = 10, autoWidth = TRUE)) 

```

## 5. Lorenz curve

```{r}

lorenz <- function(income, weights) {
  data <- tibble(Income = income, Weights = weights)

  # Calculate weighted income and sort
  data <- data %>% 
    mutate(WeightedIncome = Income * Weights) %>%
    arrange(Income)

  # Calculate cumulative weights and cumulative weighted income
  data <- data %>%
    mutate(CumulativeWeight = cumsum(Weights),
           CumulativeIncome = cumsum(WeightedIncome))

  # Total weights and total income
  total_weight <- sum(data$Weights)
  total_income <- sum(data$WeightedIncome)

  # Divide data into 100 bins based on cumulative weights
  bin_edges <- seq(0, total_weight, length.out = 101)
  data_bins <- map2_df(bin_edges[-length(bin_edges)], bin_edges[-1], ~{
    bin_start <- .x
    bin_end <- .y
    bin_data <- data %>%
      filter(CumulativeWeight > bin_start, CumulativeWeight <= bin_end)
    tibble(
      PopulationShare = bin_end / total_weight,
      IncomeShare = sum(bin_data$WeightedIncome) / total_income
    )
  })

  return(PopulationShare, IncomeShare, data_bins)
}
```

## 6. Gini coefficient

```{r}

# I found a function from the World Bank in R that computes  Gini coefficient:

md_compute_gini <- function(welfare, weight) {

  # Compute weighted welfare
  weighted_welfare <- welfare * weight
  weighted_welfare_lag <- collapse::flag(weighted_welfare, fill = 0)

  # Compute area under the curve using
  # Area of trapezoid = Base * Average height
  v <- (cumsum(weighted_welfare_lag) + (weighted_welfare / 2)) * weight
  auc <- sum(v) # Area Under the Curve

  # Compute Area Under the Lorenz Curve
  # Normalize auc so it is always between 0 and 0.5
  auc <- (auc / sum(weight)) / sum(weighted_welfare)

  # Compute Gini
  gini <- 1 - (2 * auc)

  return(gini)
}
```
